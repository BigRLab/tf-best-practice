# YAML settings for the model parameters
default: &DEFAULT
  batch_size: 32
  cell: lstm
  dilation: [1, 2, 4, 8, 16, 32]
  num_units:
    embedding: 19  # size of the embedding layer
    encoder: 17
    decoder: 17  # must be same as encoder for now
    attention: 17  # when using luong attention, must be same as encoder
  num_epoch: 1000
  optimizer: rmsp
  learning_rate: 1.0e-4
  num_eval: 100  # hold-out set for evaluation
  train_step: 10  # do inference after every x steps
  freqword_as_char: 400
  context_lines: 3  # number of lines as the context
  infer:
    len_sequence: 100
    num_line: 100
    sampling: greedy  # or greedy, or beam (not implemented yet)
  share_cell: true
  reserved_char:
    unknown: 0
    start: 1
    end: 2
  reserved_lang:
    unknown: 0
  loss: xentropy
  train_loghook: true
  gradient_clipping: true
  max_gradient_norm: 5

lstm: &LSTM
  <<: *DEFAULT
  cell: lstm
  batch_size: 128
  train_step: 20000
  num_eval: 1000
  context_lines: 10
  train_loghook: false
  num_units:
    embedding: 128  # size of the embedding layer
    encoder: 128
    decoder: 128  # must be same as encoder for now
    attention: 128  # when using luong attention, must be same as encoder

sru:
  <<: *LSTM
  cell: sru

gru:
  <<: *LSTM
  cell: gru
