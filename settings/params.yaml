# YAML settings for the model parameters
default: &DEFAULT
  batch_size: 32
  cell: lstm
  dilation: [1, 2, 4, 8, 16, 32]
  num_units:
    encoder: 17
    decoder: 17
    attention: 17
  num_epoch: 1000
  optimizer: rmsp
  learning_rate: 1.0e-4
  num_eval: 100
  train_step: 100
  infer_seq_length: 100
  dim_embed: 19
  freqword_as_char: 400
  context_lines: 3  # number of lines as the context
  max_infer_line: 100
  share_cell: true
  reserved_char:
    unknown: 0
    start: 1
    end: 2
  reserved_lang:
    unknown: 0
  loss: xentropy
  train_loghook: true
  gradient_clipping: true
  max_gradient_norm: 5
  bilevel: true

lstm: &LSTM
  <<: *DEFAULT
  cell: lstm
  batch_size: 128
  train_step: 20000
  num_eval: 1000
  dim_embed: 128
  infer_seq_length: 80
  context_lines: 10
  train_loghook: false

sru:
  <<: *LSTM
  cell: sru

gru:
  <<: *LSTM
  cell: gru
